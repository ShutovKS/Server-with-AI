#################################
# LLM CONFIGURATION
#################################

# Основная LLM-модель
LLM_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
# Можно переключаться на другие модели, просто раскомментируй нужные строки:
# LLM_MODEL=deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
# LLM_MODEL=Qwen/Qwen2.5-0.5B-Instruct
# LLM_MODEL=Qwen/Qwen2.5-VL-7B-Instruct
# LLM_MODEL=Qwen/Qwen2.5-7B

# Максимальное количество новых токенов при генерации ответа
LLM_MAX_NEW_TOKENS=1024

# Провайдер LLM (или платформа)
LLM_PROVIDER=lm-studio
# LLM_PROVIDER=huggingface

# Базовый URL, если используем lm-studio (или другой локальный сервис)
LM_STUDIO_BASE_URL=http://localhost:1234/v1

# Локальная модель или внешняя (True/False)
LOCAL_LLM_USE=True


#################################
# EMBEDDING CONFIGURATION
#################################

# Модель эмбеддингов
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Размерность эмбеддингов
EMBEDDING_DIM=1024
# Бэкенд (PyTorch, TensorFlow и т.п.)
EMBEDDING_BACKEND=torch


#################################
# CHUNK SETTINGS
#################################

# Максимальный размер одного «куска» текста
CHUNK_SIZE=2048
# Насколько сильно куски должны перекрываться
CHUNK_OVERLAP=256


#################################
# STORAGE / CACHE
#################################

# Директория для кеша
STORAGE_CACHE_DIR=.cache
# Путь для хранилища файлов
STORAGE_PATH=storage
# Путь для хранилища Chroma
CHROMA_PATH=storage
# Данные (исходные файлы, документы и т.п.)
DATA_DIR=data

# Настройки телеметрии
ANONYMIZED_TELEMETRY=False


#################################
# APPLICATION SETTINGS
#################################

# Хост и порт для веб-приложения
APP_HOST=localhost
APP_PORT=8000


#################################
# SYSTEM PROMPT
#################################

SYSTEM_PROMPT="Вы — полезный помощник, помогающий пользователям с их вопросами.
У вас есть доступ к базе знаний, включающей факты, с которых вам следует начать, чтобы найти ответ на вопрос пользователя.
Используйте инструмент query engine для извлечения фактов из базы знаний."
